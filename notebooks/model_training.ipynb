{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.7.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# Install SReT Transformer","metadata":{}},{"cell_type":"code","source":"!pip install git+https://github.com/rwightman/pytorch-image-models.git\n!pip install einops\n\n!git clone https://github.com/szq0214/SReT.git temp\n!cp -r temp/* .\n!rm -rf temp","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Import Libs","metadata":{}},{"cell_type":"code","source":"# Data EDA\nfrom pathlib import Path\nimport matplotlib.pyplot as plt\nimport numpy as np\nimport pandas as pd\nimport seaborn as sns\n\n# Model Training\nimport copy\nimport time\nimport torch\nfrom skimage import io\nfrom skimage.color import gray2rgb\nfrom torchvision import transforms, utils\nfrom tqdm import tqdm\n\n# SReT Transformer\nimport SReT\n\ndevice = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2022-04-17T02:21:13.438282Z","iopub.execute_input":"2022-04-17T02:21:13.438777Z","iopub.status.idle":"2022-04-17T02:21:15.458583Z","shell.execute_reply.started":"2022-04-17T02:21:13.438670Z","shell.execute_reply":"2022-04-17T02:21:15.457533Z"},"trusted":true},"execution_count":1,"outputs":[]},{"cell_type":"code","source":"ARTISTS_CSV_PATH = Path('../input/best-artworks-of-all-time/artists.csv')\nIMAGES_PATH = Path('../input/best-artworks-of-all-time/images/images')","metadata":{"execution":{"iopub.status.busy":"2022-04-17T02:21:15.460874Z","iopub.execute_input":"2022-04-17T02:21:15.461160Z","iopub.status.idle":"2022-04-17T02:21:15.468437Z","shell.execute_reply.started":"2022-04-17T02:21:15.461126Z","shell.execute_reply":"2022-04-17T02:21:15.466690Z"},"trusted":true},"execution_count":2,"outputs":[]},{"cell_type":"markdown","source":"# Data EDA","metadata":{}},{"cell_type":"code","source":"df_artists = pd.read_csv(str(ARTISTS_CSV_PATH))\ndf_artists.head()","metadata":{"execution":{"iopub.status.busy":"2022-04-17T02:21:19.493536Z","iopub.execute_input":"2022-04-17T02:21:19.494327Z","iopub.status.idle":"2022-04-17T02:21:19.537024Z","shell.execute_reply.started":"2022-04-17T02:21:19.494287Z","shell.execute_reply":"2022-04-17T02:21:19.536211Z"},"trusted":true},"execution_count":3,"outputs":[]},{"cell_type":"markdown","source":"**Check if folders exists.**","metadata":{}},{"cell_type":"code","source":"for name in df_artists['name']:\n    image_author_path = IMAGES_PATH / name.replace(' ', '_').replace('ü', 'u╠ê')\n    if image_author_path.exists():\n        print(f'Exists! {image_author_path}')\n    else:\n        print(f'WTF! {image_author_path}')","metadata":{"execution":{"iopub.status.busy":"2022-04-17T02:21:22.358455Z","iopub.execute_input":"2022-04-17T02:21:22.359027Z","iopub.status.idle":"2022-04-17T02:21:22.488924Z","shell.execute_reply.started":"2022-04-17T02:21:22.358981Z","shell.execute_reply":"2022-04-17T02:21:22.487979Z"},"trusted":true},"execution_count":4,"outputs":[]},{"cell_type":"markdown","source":"**Check paintings quantity by each author.**","metadata":{}},{"cell_type":"code","source":"sns.set(rc={'figure.figsize':(11.7,8.27)})\nplt.xticks(rotation=90)\nsns.barplot(data=df_artists, x='name', y='paintings')","metadata":{"execution":{"iopub.status.busy":"2022-04-17T02:22:17.167047Z","iopub.execute_input":"2022-04-17T02:22:17.167912Z","iopub.status.idle":"2022-04-17T02:22:19.620834Z","shell.execute_reply.started":"2022-04-17T02:22:17.167873Z","shell.execute_reply":"2022-04-17T02:22:19.620118Z"},"trusted":true},"execution_count":6,"outputs":[]},{"cell_type":"markdown","source":"**Check quantity of authors with painting more or equal than 100.**","metadata":{}},{"cell_type":"code","source":"np.sum(df_artists['paintings'] >= 100)","metadata":{"execution":{"iopub.status.busy":"2022-04-17T02:24:10.048894Z","iopub.execute_input":"2022-04-17T02:24:10.049432Z","iopub.status.idle":"2022-04-17T02:24:10.055916Z","shell.execute_reply.started":"2022-04-17T02:24:10.049392Z","shell.execute_reply":"2022-04-17T02:24:10.055063Z"},"trusted":true},"execution_count":8,"outputs":[]},{"cell_type":"markdown","source":"# Prepare Data for model training","metadata":{}},{"cell_type":"markdown","source":"**Only keep authors with more than 100 paintings.**","metadata":{}},{"cell_type":"code","source":"df_artists_model = df_artists.drop(df_artists[df_artists['paintings'] < 100].index)\nprint(f'Records: {len(df_artists_model)}')\ndf_artists_model.head()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"**Create Pytorch dataset model.**","metadata":{}},{"cell_type":"code","source":"class ArtistsPaintingsDataset(torch.utils.data.Dataset):\n    def __init__(self, df_artists: pd.DataFrame, images_path: Path, min_author_idx:int, max_author_idx:int, transform=None):\n        self.df_artists = df_artists\n        self.images_path = images_path\n        self.transform = transform\n        self.min_author_idx = min_author_idx\n        self.max_author_idx = max_author_idx\n\n    def __len__(self):\n        return (self.max_author_idx - self.min_author_idx) * len(self.df_artists)\n\n    def __getitem__(self, idx):\n        if torch.is_tensor(idx):\n            idx = idx.tolist()\n        \n        image_quantity_per_author = self.max_author_idx - self.min_author_idx\n        author_id = idx // image_quantity_per_author\n        author_image_id = idx % image_quantity_per_author + self.min_author_idx + 1 \n        \n        author_name = self.df_artists['name'].iloc[author_id].replace(' ', '_').replace('ü', 'u╠ê')\n        image_path = self.images_path / author_name / f'{author_name}_{author_image_id}.jpg'\n        image = io.imread(image_path)\n\n        if len(image.shape) == 2 or image.shape[2] == 1:\n            image = gray2rgb(image)\n        \n        if self.transform:\n            image = self.transform(image)\n        \n        sample={'image': image, 'author_id': torch.from_numpy(np.array(int(author_id)))}\n        return sample","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"**Intialize Train/Test datasets and dataloaders with simple augmentations.**","metadata":{}},{"cell_type":"code","source":"transforms_train = transforms.Compose([\n    transforms.ToTensor(),\n    transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225]),\n    transforms.RandomVerticalFlip(0.5),\n    transforms.RandomHorizontalFlip(0.5),\n    transforms.Resize(380),\n    transforms.RandomCrop(380)\n#     transforms.Resize(224),\n#     transforms.RandomCrop(224)\n])\n\ntransforms_test = transforms.Compose([\n    transforms.ToTensor(),\n    transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225]),\n    transforms.Resize(380),\n    transforms.RandomCrop(380)\n#     transforms.Resize(224),\n#     transforms.RandomCrop(224)\n])\n\n\n\nbatch_size = 128\n\ntrain_dataset = ArtistsPaintingsDataset(df_artists=df_artists_model, images_path=IMAGES_PATH, min_author_idx=0, max_author_idx=75, transform=transforms_train)\ntest_dataset = ArtistsPaintingsDataset(df_artists=df_artists_model, images_path=IMAGES_PATH, min_author_idx=75, max_author_idx=100, transform=transforms_test)\n\ntrain_loader = torch.utils.data.DataLoader(train_dataset, batch_size=batch_size, shuffle=True, num_workers=2)\ntest_loader = torch.utils.data.DataLoader(test_dataset, batch_size=batch_size, shuffle=True, num_workers=2)\n\ndataset_sizes = {'train': len(train_dataset), 'test': len(test_dataset)}","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Model Training","metadata":{}},{"cell_type":"markdown","source":"**Implement training function.**","metadata":{}},{"cell_type":"code","source":"def train_model(model, criterion, optimizer, scheduler, dataloaders, num_epochs=25):\n    since = time.time()\n\n    best_model_wts = copy.deepcopy(model.state_dict())\n    best_acc = 0.0\n\n    for epoch in range(num_epochs):\n        print(f'Epoch {epoch}/{num_epochs - 1}')\n        print('-' * 10)\n\n        # Each epoch has a training and validation phase\n        for phase in ['train', 'test']:\n            if phase == 'train':\n                model.train()  # Set model to training mode\n            else:\n                model.eval()   # Set model to evaluate mode\n\n            running_loss = 0.0\n            running_corrects = 0\n\n            # Iterate over data.\n            for samples in tqdm(dataloaders[phase]):\n                inputs = samples['image'].to(device)\n                labels = samples['author_id'].to(device)\n\n                # zero the parameter gradients\n                optimizer.zero_grad()\n\n                # forward\n                # track history if only in train\n                with torch.set_grad_enabled(phase == 'train'):\n                    outputs = model(inputs)\n                    _, preds = torch.max(outputs, 1)\n                    loss = criterion(outputs, labels)\n\n                    # backward + optimize only if in training phase\n                    if phase == 'train':\n                        loss.backward()\n                        optimizer.step()\n\n                # statistics\n                running_loss += loss.item() * inputs.size(0)\n                running_corrects += torch.sum(preds == labels.data)\n            if phase == 'train':\n                scheduler.step()\n\n            epoch_loss = running_loss / dataset_sizes[phase]\n            epoch_acc = running_corrects.double() / dataset_sizes[phase]\n\n            print(f'{phase} Loss: {epoch_loss:.4f} Acc: {epoch_acc:.4f}')\n\n            # deep copy the model\n            if phase == 'test' and epoch_acc > best_acc:\n                best_acc = epoch_acc\n                best_model_wts = copy.deepcopy(model.state_dict())\n\n        print()\n\n    time_elapsed = time.time() - since\n    print(f'Training complete in {time_elapsed // 60:.0f}m {time_elapsed % 60:.0f}s')\n    print(f'Best test Acc: {best_acc:4f}')\n\n    # load best model weights\n    model.load_state_dict(best_model_wts)\n    return model","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"**Download model for training (need to uncomment a model which you want to train).**","metadata":{}},{"cell_type":"code","source":"# # EFFICIENTNET-B4\n# model = torch.hub.load('NVIDIA/DeepLearningExamples:torchhub', 'nvidia_efficientnet_b4', pretrained=True)\n\n# # RESNET-50\n# model = torch.hub.load('NVIDIA/DeepLearningExamples:torchhub', 'nvidia_resnet50', pretrained=True)\n\n# # SReT_S\n# model = SReT.SReT_S(pretrained=False)\n# model.load_state_dict(torch.load('../input/sret-s-pth/SReT_S.pth')['model'])","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"**Freeze/unfreeze some layers for training (need to uncomment a model which you want to train).**","metadata":{}},{"cell_type":"code","source":"for param in model.parameters():\n    param.requires_grad = False\n\n# # EFFICIENTNET-B4\n# model.features.requires_grad_(True)\n# model.classifier.requires_grad_(True)\n# model.classifier.fc = torch.nn.Linear(1792, 30)\n\n# # RESNET-50\n# model.fc = torch.nn.Linear(2048, 30)\n\n# # SReT_S\n# for idx, param in enumerate(model.transformers[2].parameters()):\n#     if idx > 80: \n#         param.requires_grad = True\n# model.norm.requires_grad_(True)\n# model.avgpool.requires_grad_(True)\n# model.head.requires_grad_(True)\n# model.head = torch.nn.Linear(504, 30)\n\nmodel.cuda()\nprint()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"**Running a training.**","metadata":{}},{"cell_type":"code","source":"criterion = torch.nn.CrossEntropyLoss()\noptimizer = torch.optim.Adam(model.parameters(), lr=0.001)\nscheduler = torch.optim.lr_scheduler.StepLR(optimizer, step_size=5, gamma=0.33)\nbest_model = train_model(model, criterion, optimizer, scheduler, {'train': train_loader, 'test': test_loader}, num_epochs=15) ","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"**Saving model weights.**","metadata":{}},{"cell_type":"code","source":"# # EFFICIENTNET-B4\n# torch.save(model.state_dict(), 'efficient_b4_03.pt')\n\n# # RESNET-50\n# torch.save(model.state_dict(), 'resnet_50_01.pt')\n\n# # SReT_S\n# torch.save(model.state_dict(), 'sret-s_01.pt')","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"**Saving authors dataframe which were taken for the training.**","metadata":{}},{"cell_type":"code","source":"df_artists_model.to_csv('artists.csv', index=False)","metadata":{"trusted":true},"execution_count":null,"outputs":[]}]}